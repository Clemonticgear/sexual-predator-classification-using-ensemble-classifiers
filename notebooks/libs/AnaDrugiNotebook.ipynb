{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import sys\n",
    "from lxml import etree\n",
    "sys.path.insert(0, '../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathToFile='../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "tree=etree.parse(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ovo nije potrebno\n",
    "def generator_author_and_conversation(dictionary):\n",
    "    for key in dictionary:\n",
    "        data = [dictionary.get(key)]\n",
    "        data.insert(0,key)\n",
    "        yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_words_from_dictionary(dictionary):\n",
    "    regex1 = re.compile(r'(.)\\1{5,}')\n",
    "    regex2 = re.compile(r'^[0-9]*$')\n",
    "    for key in dictionary:\n",
    "        text = dictionary.get(key)\n",
    "        if None in text:\n",
    "            continue\n",
    "        text = [x for x in text if len(x)<20]\n",
    "        text = [i for i in text if not regex1.search(i)]\n",
    "        text = [i for i in text if not regex2.search(i)]\n",
    "        dictionary[key] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function returns author - term matrix \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def make_tf_idf_matrix_from_XML(pathToFile):\n",
    "    tree=etree.parse(pathToFile)\n",
    "    message_node = FE.extract_message_nodes_as_list_from_parsed_text(tree)\n",
    "    dictionary= FE.extract_author_text_dictionary_from_message_nodes(message_node)\n",
    "    filter_words_from_dictionary(dictionary)\n",
    "    list_of_authors_strings = []\n",
    "    for key in dictionary:\n",
    "        tmp = dictionary.get(key)\n",
    "        if None in tmp:\n",
    "            continue\n",
    "        list_of_authors_strings.append(' '.join(dictionary.get(key)))\n",
    "    tfidf=TfidfVectorizer(stop_words='english',min_df=10)\n",
    "    #X = tfidf.fit_transform(list_of_authors_strings)\n",
    "    #idf = tfidf._tfidf\n",
    "    return tfidf.fit_transform(list_of_authors_strings), tfidf.get_feature_names(), list(dictionary.keys())\n",
    "    #return dict(zip(tfidf.get_feature_names(), idf))\n",
    "    #return tfidf.get_feature_names(),idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = {\"ana\" : [\"sibenik\",\"zagreb\"], \"petra\":[\"makarska\",\"zagreb\",\"blaaaaaaaaaaaaaaaaaaaaaaaaaa\"],\"vinko\":[\"nestttttto\",\"blaaa\",\"099911\",\"007\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vinko': ['blaaa'], 'ana': ['sibenik', 'zagreb'], 'petra': ['makarska', 'zagreb']}\n"
     ]
    }
   ],
   "source": [
    "filter_words_from_dictionary(a)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix,names,authors = make_tf_idf_matrix_from_XML(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n",
      "deset\n"
     ]
    }
   ],
   "source": [
    "#fo = open(\"tf_idf.csv\",\"w\")\n",
    "\n",
    "#row = matrix.shape[0]\n",
    "row = 100\n",
    "col = matrix.shape[1]\n",
    "#col = 100\n",
    "lines = []\n",
    "big_lines=[]\n",
    "#buff_cnt = 0\n",
    "with open('tf_idf_test.csv',\"w+\") as fo:\n",
    "    a = [\"author_ID\"]\n",
    "    for i in range(0,col):\n",
    "        a.append(names[i].encode(\"utf-8\"))\n",
    "    fo.write(','.join(a) + '\\n')\n",
    "\n",
    "    for i in range(0, row):\n",
    "        lines.append(authors[i])\n",
    "        matrix[i:]\n",
    "        for j in range(0,col):\n",
    "            lines.append(matrix[i,j])\n",
    "            \n",
    "        big_lines.append(','.join(map(str, lines))+'\\n') #print lines[i]\n",
    "        lines=[]\n",
    "        if len(big_lines)==10:\n",
    "            print \"deset\"\n",
    "            #print len(big_lines)\n",
    "            #print lines[0]\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            big_lines=[]\n",
    "        elif i == (col-1):\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n",
      "deset somova\n"
     ]
    }
   ],
   "source": [
    "row = matrix.shape[0]\n",
    "#row = 1000\n",
    "col = matrix.shape[1]\n",
    "#col = 100\n",
    "lines = []\n",
    "big_lines=[]\n",
    "#buff_cnt = 0\n",
    "str_buff = \"\"\n",
    "with open('tf_idf_test.csv',\"w+\") as fo:\n",
    "    a = [\"author_ID\"]\n",
    "    for i in range(0,col):\n",
    "        a.append(names[i].encode(\"utf-8\"))\n",
    "    fo.write(','.join(a) + '\\n')\n",
    "\n",
    "    for i in range(0, row):\n",
    "        str_buff = authors[i]+','\n",
    "        mat = np.ravel(matrix[i].todense())\n",
    "        mat = [str(x) for x in mat]\n",
    "        str_buff+=(','.join(mat)+'\\n')\n",
    "        big_lines.append(str_buff) #print lines[i]\n",
    "        str_buff=\"\"\n",
    "        if len(big_lines)==10000:\n",
    "            print \"deset somova\"\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            big_lines=[]\n",
    "        elif i == (row-1):\n",
    "            for line in big_lines:\n",
    "                fo.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97377, 3083)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = matrix[18].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ravelana = np.ravel(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print str(ravelana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ravelana = [str(x) for x in ravelana]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fajl = pd.read_csv(\"tf_idf_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97377, 3084)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fajl.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
