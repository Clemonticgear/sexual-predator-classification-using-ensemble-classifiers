{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import itertools\n",
    "import sklearn.metrics as met\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy as sp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('../../csv/chat_based_features_training.csv')\n",
    "test = pd.read_csv('../../csv/chat_based_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering chat based\n",
    "#minimal_number_of_messages_treshold = 2\n",
    "#training = training[training['number of messages sent'] >= minimal_number_of_messages_treshold]\n",
    "#test = test[test['number of messages sent'] >= minimal_number_of_messages_treshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "\n",
    "important_features = ['percent of conversations started by the author',\n",
    "                      'difference between two preceding lines in seconds', 'number of messages sent',\n",
    "                      'average percent of lines in conversation', \n",
    "                      \n",
    "                      'number of characters sent by the author', 'mean time of messages sent',\n",
    "                      \n",
    "                      'avg number of unique authors interacted with per conversation', \n",
    "                      'total unique authors and unique per chat difference',\n",
    "                \n",
    "                      'total question marks',\n",
    "                      'total author question marks', 'avg author question marks',\n",
    "                      'author and conversation quetsion mark differnece', 'pos word count author',\n",
    "                      'prof word count author']\n",
    "#training_sparse = sp.sparse.csr_matrix(training[features].ix[:,1:].values, dtype=float)[:,:-1]\n",
    "#test_sparse = sp.sparse.csr_matrix(test[features].ix[:,1:].values, dtype=float)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_xml = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "test_xml = '../../dataset/test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering TF-IDF\n",
    "# Original documents_training = FE.prepare_for_tf_idf(training_xml, False)\n",
    "\n",
    "documents_training = FE.prepare_for_tf_idf(training_xml, False)\n",
    "documents_test = FE.prepare_for_tf_idf(test_xml, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english', min_df=3, max_features=2500) #max_features=2500\n",
    "matrix_training=tfidf.fit_transform(documents_training)\n",
    "matrix_testing=tfidf.transform(documents_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print matrix_training.shape\n",
    "#print training_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = training.columns.values.tolist()[1:-1]\n",
    "print column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_all = sp.sparse.hstack((training[column_names], matrix_training))\n",
    "test_all = sp.sparse.hstack((test[column_names], matrix_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler(with_mean=False)\n",
    "training_all=scaler.fit_transform(training_all)\n",
    "test_all=scaler.transform(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_all = normalize(training_all, norm='l1', axis=1)\n",
    "#test_all = normalize(test_all, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=13, n_estimators=280, learning_rate=0.028, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step=3)\n",
    "\n",
    "model.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.f1_score(test[['is sexual predator']], prediction)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(max_depth=13, n_estimators=280, learning_rate=0.065, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step=5)\n",
    "Accuracy:  0.999446735741\n",
    "Precision:  0.803652968037\n",
    "Recall: 0.692913385827\n",
    "F1: 0.744186046512\n",
    "F0.5: 0.778761061947\n",
    "\n",
    "(max_depth=13, n_estimators=280, learning_rate=0.28, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step\n",
    "Accuracy:  0.999437590877\n",
    "Precision:  0.819512195122\n",
    "Recall: 0.661417322835\n",
    "F1: 0.732026143791\n",
    "F0.5: 0.782122905028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = training.columns.values.tolist()[1:-1]\n",
    "print column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove scale_post_weight -> smaller F1 score, lower recall but increase precision\n",
    "# Remove gama for bigger precision\n",
    "sex_offender0 = xgb.XGBClassifier(max_depth=13, n_estimators=280, learning_rate=0.028, scale_pos_weight=5, gamma=4,\n",
    "                          min_child_weight=5, subsample=1, max_delta_step=3)\n",
    "sex_offender1 = xgb.XGBClassifier(max_depth=25, n_estimators=300)\n",
    "sex_offender2 = xgb.XGBClassifier(max_depth=5, n_estimators=220, learning_rate=0.007, scale_pos_weight=20, gamma=2)\n",
    "sex_offender3 = xgb.XGBClassifier(max_depth=3, n_estimators=400)\n",
    "sex_offender4 = xgb.XGBClassifier(max_depth=7, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sex_offender0.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender1.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender2.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender3.fit(training_all, training[['is sexual predator']])\n",
    "sex_offender4.fit(training_all, training[['is sexual predator']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction0 = sex_offender0.predict(test_all)\n",
    "prediction1 = sex_offender1.predict(test_all)\n",
    "prediction2 = sex_offender2.predict(test_all)\n",
    "prediction3 = sex_offender3.predict(test_all)\n",
    "prediction4 = sex_offender4.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging(vote_number, prediction_list):\n",
    "    total_prediction = []\n",
    "    for i in range(len(prediction_list[0])):\n",
    "        voters = 0\n",
    "        \n",
    "        for prediction in prediction_list:\n",
    "            if prediction[i] == 1:\n",
    "                voters += 1\n",
    "                \n",
    "        if voters >= vote_number:\n",
    "            total_prediction.append(1)\n",
    "        else:\n",
    "            total_prediction.append(0)\n",
    "                \n",
    "    return np.array(total_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = bagging(5, [prediction0, prediction1, prediction2, prediction3, prediction4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "max_f1 = 0\n",
    "best_features = []\n",
    "\n",
    "for num_features in range(2, len(column_names)-1):\n",
    "    for column_name_subset in itertools.combinations(column_names, num_features):\n",
    "\n",
    "        forest = forest.fit(training[list(column_name_subset)], np.ravel(training.iloc[:,[9]]))\n",
    "        prediction = forest.predict(test[list(column_name_subset)])\n",
    "\n",
    "        print column_name_subset\n",
    "        print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "        print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "        print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "        print 'F1:', met.f1_score(test[['is sexual predator']], prediction)\n",
    "        print \"\\n\\n\"\n",
    "\n",
    "        f1 = met.f1_score(test[['is sexual predator']], prediction)\n",
    "        if max_f1 < f1:\n",
    "            max_f1 = f1\n",
    "            best_features =  column_name_subset\n",
    "                                                                                                 \n",
    "print max_f1\n",
    "print best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "features = training.columns.values.tolist()[1:-1]\n",
    "x_train = training_all\n",
    "y_train = training['is sexual predator']\n",
    "ceate_feature_map(features)\n",
    "\n",
    "xgb_params = {\"objective\": \"binary:logistic\", \"eta\": 0.01, \"max_depth\": 8, \"seed\": 42, \"silent\": 1}\n",
    "num_rounds = 30\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "gbdt = xgb.train(xgb_params, dtrain, num_rounds)\n",
    "\n",
    "importance = gbdt.get_fscore(fmap='xgb.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "plt.figure()\n",
    "df.plot()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.gcf().savefig('feature_importance_xgb.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_all, label=test['is sexual predator'])\n",
    "gbdt.fit(dtest[predictors], dtest['is sexual preadtor'],eval_metric='auc')\n",
    "prediction = gbdt.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.to_graphviz(gbdt, num_trees=2)\n",
    "#print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Accuracy: ', met.accuracy_score(test[['is sexual predator']], prediction) \n",
    "print 'Precision: ', met.precision_score(test[['is sexual predator']], prediction)\n",
    "print 'Recall:', met.recall_score(test[['is sexual predator']], prediction)\n",
    "print 'F1:', met.fbeta_score(test[['is sexual predator']], prediction, 1)\n",
    "print 'F0.5:', met.fbeta_score(test[['is sexual predator']], prediction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "target = 'is sexual predator'\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['is sexual preadtor'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['is sexual preadtor'].values, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['is sexual preadtor'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = training.columns.values.tolist()[1:-1]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, training, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
