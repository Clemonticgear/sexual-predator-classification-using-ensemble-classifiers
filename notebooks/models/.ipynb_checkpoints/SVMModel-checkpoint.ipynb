{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "sys.path.insert(0, '../../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../libs/')\n",
    "%matplotlib inline\n",
    "\n",
    "import FeatureExtraction\n",
    "from lxml import etree\n",
    "\n",
    "training_xml = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "test_xml = '../../dataset/test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml'\n",
    "\n",
    "sexual_predator_ids_file = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt'\n",
    "\n",
    "chat_based_features_csv_train='../../csv/chat_based_features_training.csv'\n",
    "chat_based_features_csv_test='../../csv/chat_based_features_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#matrix_training, matrix_testing = FE.make_tf_idf_matrix_from_XML(training_xml, test_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_training=FE.prepare_for_tf_idf(training_xml,False)\n",
    "document_testing=FE.prepare_for_tf_idf(test_xml,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97689\n",
      "218702\n"
     ]
    }
   ],
   "source": [
    "print(len(documents_training))\n",
    "print(len(document_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english',min_df=3,max_features=3500)\n",
    "matrix_training=tfidf.fit_transform(documents_training)\n",
    "matrix_testing=tfidf.transform(document_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_frame=pd.DataFrame(pd.read_csv(chat_based_features_csv_train))\n",
    "test_frame=pd.DataFrame(pd.read_csv(chat_based_features_csv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "X_train_chat_based=train_frame.ix[:,features]\n",
    "y_train=np.ravel(train_frame[[-1]])\n",
    "X_test_chat_based=test_frame.ix[:,features]\n",
    "y_test=np.ravel(test_frame[[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((97689, 2005), (97689L,), (218702, 2005), (218702L,))\n"
     ]
    }
   ],
   "source": [
    "X_train = sp.sparse.hstack((X_train_chat_based, matrix_training))\n",
    "X_test = sp.sparse.hstack((X_test_chat_based, matrix_testing))\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler(with_mean=False)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=100, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svmc=svm.SVC(kernel='linear',max_iter=100)\n",
    "lrc=linear_model.LogisticRegression(n_jobs=8,max_iter=100000,penalty='l2')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaler=StandardScaler(with_mean=False)\n",
    "#matrix_training=scaler.fit_transform(matrix_training)\n",
    "#matrix_testing=scaler.transform(matrix_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#linearsvm=svm.LinearSVC(max_iter=1000)\n",
    "#ovaj samo na tf idf daje f-score 59 uz tf idf napravljen sa TfidfVectorizer(stop_words='english',min_df=3,max_features=3500)\n",
    "classifier=svm.SVC(C=0.4,kernel='linear',max_iter=100)\n",
    "classifier.fit(matrix_training,y_train)\n",
    "predicted_test=classifier.predict(matrix_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "(218702L,)\n",
      "(218702L,)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_test[predicted_test==1])\n",
    "print(predicted_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test statistics\n",
      "('acc', 0.99923183144187067)\n",
      "('rec', 0.48031496062992124)\n",
      "('prec', 0.77215189873417722)\n",
      "('f1', 0.59223300970873793)\n",
      "('f0.5', 0.68848758465011295)\n"
     ]
    }
   ],
   "source": [
    "#print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "print(\"\\ntest statistics\")\n",
    "print('acc',accuracy_score(y_test,predicted_test))\n",
    "print('rec',recall_score(y_test,predicted_test))\n",
    "print('prec',precision_score(y_test,predicted_test))\n",
    "print('f1',f1_score(y_test,predicted_test))\n",
    "print('f0.5',fbeta_score(y_test,predicted_test,0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
