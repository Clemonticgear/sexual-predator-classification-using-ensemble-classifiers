{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "sys.path.insert(0, '../../notebooks/libs/')\n",
    "import FeatureExtraction as FE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../libs/')\n",
    "%matplotlib inline\n",
    "\n",
    "import FeatureExtraction\n",
    "from lxml import etree\n",
    "\n",
    "training_xml = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-2012-05-01.xml'\n",
    "test_xml = '../../dataset/test/pan12-sexual-predator-identification-test-corpus-2012-05-17.xml'\n",
    "\n",
    "sexual_predator_ids_file = '../../dataset/training/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt'\n",
    "\n",
    "chat_based_features_csv_train='../../csv/chat_based_features_training.csv'\n",
    "chat_based_features_csv_test='../../csv/chat_based_features_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#matrix_training, matrix_testing = FE.make_tf_idf_matrix_from_XML(training_xml, test_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prepare_for_tf_idf() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f9c7c2e07565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocuments_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_for_tf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_xml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdocument_testing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_for_tf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_xml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: prepare_for_tf_idf() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "documents_training=FE.prepare_for_tf_idf(training_xml,False)\n",
    "document_testing=FE.prepare_for_tf_idf(test_xml,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97689\n",
      "218702\n"
     ]
    }
   ],
   "source": [
    "print(len(documents_training))\n",
    "print(len(document_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(stop_words='english',min_df=10)\n",
    "matrix_training=tfidf.fit_transform(documents_training)\n",
    "matrix_testing=tfidf.transform(document_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-72f237689c6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautor_conversation_dictionay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatureExtraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_author_conversation_node_dictionary_from_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msexual_predator_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFeatureExtraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msexual_predator_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msexual_predator_ids_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_tree' is not defined"
     ]
    }
   ],
   "source": [
    "autor_conversation_dictionay = FeatureExtraction.extract_author_conversation_node_dictionary_from_XML(training_tree)\n",
    "sexual_predator_ids = FeatureExtraction.sexual_predator_ids(sexual_predator_ids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_frame=pd.DataFrame(pd.read_csv(chat_based_features_csv_train))\n",
    "test_frame=pd.DataFrame(pd.read_csv(chat_based_features_csv_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((97689, 1379), (97689L,), (218702, 1379), (218702L,))\n"
     ]
    }
   ],
   "source": [
    "features=['number of conversation', 'percent of conversations started by the author', 'number of messages sent', 'average percent of lines in conversation', 'number of characters sent by the author']\n",
    "X_train_chat_based=train_frame.ix[:,features]\n",
    "y_train=np.ravel(train_frame[[-1]])\n",
    "X_test_chat_based=test_frame.ix[:,features]\n",
    "y_test=np.ravel(test_frame[[-1]])\n",
    "\n",
    "X_train = sp.sparse.hstack((X_train_chat_based, matrix_training))\n",
    "X_test = sp.sparse.hstack((X_test_chat_based, matrix_testing))\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler(with_mean=False)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "svmc=svm.SVC()\n",
    "linearsvm=svm.LinearSVC(max_iter=100000)\n",
    "lrc=linear_model.LogisticRegression(n_jobs=8,max_iter=1000000,penalty='l1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97689, 1374)\n"
     ]
    }
   ],
   "source": [
    "print(matrix_training.shape)\n",
    "classifier=lrc\n",
    "classifier.fit(matrix_training,y_train)\n",
    "#samo tf idf\n",
    "predicted_train=classifier.predict(matrix_training)\n",
    "predicted_test=classifier.predict(matrix_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier=linearsvm\n",
    "classifier.fit(X_train,y_train)\n",
    "predicted_train=classifier.predict(X_train)\n",
    "predicted_test=classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_test[predicted_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"train statistics\")\n",
    "print('acc',accuracy_score(y_train,predicted_train))\n",
    "print('rec',recall_score(y_train,predicted_train))\n",
    "print('prec',precision_score(y_train,predicted_train))\n",
    "print('f1',f1_score(y_train,predicted_train))\n",
    "\n",
    "print(\"\\ntest statistics\")\n",
    "print('acc',accuracy_score(y_test,predicted_test))\n",
    "print('rec',recall_score(y_test,predicted_test))\n",
    "print('prec',precision_score(y_test,predicted_test))\n",
    "print('f1',f1_score(y_test,predicted_test))\n",
    "print('f0.5',fbeta_score(y_test,predicted_test,0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
